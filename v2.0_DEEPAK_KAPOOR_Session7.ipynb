{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testerkaps_v2.0_DEEPAK_KAPOOR_Session7.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hvVgBfsN_TKo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e3f06012-930f-43ff-f54c-6d508638a351",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529233314414,
          "user_tz": -330,
          "elapsed": 4509,
          "user": {
            "displayName": "Deepak Kapoor",
            "photoUrl": "//lh5.googleusercontent.com/-GVWsDyyzZr0/AAAAAAAAAAI/AAAAAAAAAnY/iN0iMyP85Xg/s50-c-k-no/photo.jpg",
            "userId": "104384291973067307940"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Check if your runtime is GPU accelerated or not\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "hw = device_lib.list_local_devices()\n",
        "#print(hw)\n",
        "if \"GPU\" in str(hw):\n",
        "  print(\"Your runtime is GPU accelerated\")\n",
        "else:\n",
        "  print(\"Change runtime to GPU accelerated\")\n",
        "!ls\n",
        "!ls datalab/\n",
        "!ls datalab/*/ | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime is GPU accelerated\n",
            "datalab\n",
            "adc.json  median_filter_out  test  train  train_cleaned\n",
            "439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MZHU_bceThPb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "229a63d5-d9f3-4a53-e7eb-eb430b8c3699",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529169984568,
          "user_tz": -330,
          "elapsed": 27451,
          "user": {
            "displayName": "Tester",
            "photoUrl": "//lh5.googleusercontent.com/-qA8vaqLPJz4/AAAAAAAAAAI/AAAAAAAAABM/Dw8MfZNwdeI/s50-c-k-no/photo.jpg",
            "userId": "111793042070986861735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def check_number_of_pixels_imgdir(in_path):\n",
        "  '''\n",
        "  Number of Predictions (mandated by competition):\n",
        "  We expect the solution file to have 14230080 prediction rows. This file should have a header row. Please see sample submission file on the data page.\n",
        "  Below function calculates total entries arrived at using formula = (#images*img.shape[0]*img.shape[1])\n",
        "  '''\n",
        "  \n",
        "  import os\n",
        "  \n",
        "  t=0\n",
        "  for f in os.listdir(in_path):\n",
        "    inp_path = in_path+f\n",
        "    out_path = 'datalab/out/'+f\n",
        "\n",
        "    inp = load_image(inp_path)\n",
        "    out = denoise_image(inp)\n",
        "    save(out_path, out)\n",
        "    \n",
        "    img = np.asarray(Image.open(out_path))\n",
        "    t += img.shape[0]*img.shape[1]\n",
        "  return t\n",
        "\n",
        "tick=time.time()\n",
        "print(check_number_of_pixels_imgdir('datalab/test/'))\n",
        "tock=time.time()\n",
        "print('time taken: '+str(tock-tick))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14230080\n",
            "time taken: 26.576579332351685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HZrkEiAgOpf8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b87431eb-e3df-410a-e6b1-296c9babb51c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529241105859,
          "user_tz": -330,
          "elapsed": 19845,
          "user": {
            "displayName": "Tester",
            "photoUrl": "//lh5.googleusercontent.com/-qA8vaqLPJz4/AAAAAAAAAAI/AAAAAAAAABM/Dw8MfZNwdeI/s50-c-k-no/photo.jpg",
            "userId": "111793042070986861735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def download_dataset_to_collab(dataset):\n",
        "  '''\n",
        "  Google Drive is a tag-based (also called semantic) file system, which, for example, allows a file to be in several places at the same time \n",
        "  (just by adding IDs of folders to the file's parents property)\n",
        "  Hence to get the file/folder ID, navigate to the folder using browser & note the ID from URL \n",
        "  Ex: https://drive.google.com/drive/folders/1mZVxppM8dHFcoKdc9Vu9vS-n_GGnpCkO\n",
        "  '''\n",
        "  #Code to download files from google drive to collab using Pydrive\n",
        "\n",
        "  !pip install -U -q PyDrive\n",
        "\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  import time\n",
        "\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  # Auto-iterate through all files in the folder ID.\n",
        "  start = time.time()\n",
        "  for key, value in dataset.items():\n",
        "    print(\"Initiating files copy from {} ...\".format(key))\n",
        "    file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(value)}).GetList()      #file_list = drive.ListFile({'q': \"'1czmCOb4w0LiWetvQyhIxi6gGvJuAYb5F' in parents and trashed=false\"}).GetList()\n",
        "    for file1 in file_list:      \n",
        "      file6 = drive.CreateFile({'id': file1['id']}) # Initialize GoogleDriveFile instance with file id.\n",
        "      file6.GetContentFile(file1['title'])          # Download file as file1['title']\n",
        "    !mkdir 'datalab/'$key                           # move the data to folder in dictionary\n",
        "    !ls -l datalab/\n",
        "    !mv *.png 'datalab/'$key\n",
        "    !ls -l datalab/\n",
        "    print(\"Completed files copy from {}.\".format(key))\n",
        "\n",
        "  end = time.time()                                                                \n",
        "  return 'time taken:'+ str(end-start) +'seconds'\n",
        "\n",
        "dataset = {\n",
        "          #'<folder_name>':'<gdrive_folder_id>'\n",
        "          'train':'1mZVxppM8dHFcoKdc9Vu9vS-n_GGnpCkO', \n",
        "          'test':'1czmCOb4w0LiWetvQyhIxi6gGvJuAYb5F',\n",
        "          'train_cleaned':'1T4uCpfZueGsSUCu145FuEcPY_he6A2fQ'\n",
        "          }\n",
        "download_dataset_to_collab(dataset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed files copy from train.csv.\n",
            "Completed files copy from train_cleaned.csv.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'time taken:16.717437505722046seconds'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "QC9uV-fuDfyX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "188e8994-59cd-4e8a-93d2-eb31bfd0ec72",
        "executionInfo": {
          "status": "error",
          "timestamp": 1529258043822,
          "user_tz": -330,
          "elapsed": 854,
          "user": {
            "displayName": "Tester",
            "photoUrl": "//lh5.googleusercontent.com/-qA8vaqLPJz4/AAAAAAAAAAI/AAAAAAAAABM/Dw8MfZNwdeI/s50-c-k-no/photo.jpg",
            "userId": "111793042070986861735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Simple background removal code\n",
        "\n",
        "__author__ : Rangel Dokov\n",
        "\n",
        "The basic idea is that we have a foreground object of interest (the dark text)\n",
        "and we want to remove everything that is not part of this foreground object.\n",
        "\n",
        "This should produce results somewhere around 0.06 on the leaderboard.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def load_image(path):\n",
        "    return np.asarray(Image.open(path))/255.0\n",
        "\n",
        "def save(path, img):\n",
        "    tmp = np.asarray(img*255.0, dtype=np.uint8)\n",
        "    Image.fromarray(tmp).save(path)\n",
        "\n",
        "def denoise_image(inp):\n",
        "    # estimate 'background' color by a median filter\n",
        "    bg = signal.medfilt2d(inp, 11)\n",
        "    save('background.png', bg)\n",
        "\n",
        "    # compute 'foreground' mask as anything that is significantly darker than\n",
        "    # the background\n",
        "    mask = inp < bg - 0.1\n",
        "    save('foreground_mask.png', mask)\n",
        "\n",
        "    # return the input value for all pixels in the mask or pure white otherwise\n",
        "    return np.where(mask, inp, 1.0)\n",
        "\n",
        "inp_path = './datalab/test/76.png'\n",
        "out_path = 'output.png'\n",
        "\n",
        "inp = load_image(inp_path)\n",
        "out = denoise_image(inp)\n",
        "save(out_path, out)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ce1f12aacabf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenoise_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ce1f12aacabf>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datalab/test/76.png'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4E33tiLgdaCg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 4930
        },
        "outputId": "b44e8d18-d1d7-42fa-b413-70c461464e51",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529238094781,
          "user_tz": -330,
          "elapsed": 1939183,
          "user": {
            "displayName": "Deepak Kapoor",
            "photoUrl": "//lh5.googleusercontent.com/-GVWsDyyzZr0/AAAAAAAAAAI/AAAAAAAAAnY/iN0iMyP85Xg/s50-c-k-no/photo.jpg",
            "userId": "104384291973067307940"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def img2csv(imgdir_path,csv_name):\n",
        "  '''\n",
        "  This function flattens input image(s) from provided path to array=>(pixel_id,pixel_intensity_value)\n",
        "  '''\n",
        "  import time\n",
        "  import os\n",
        "  import numpy as np\n",
        "  from PIL import Image as Image\n",
        "  import csv\n",
        "  img_no=1\n",
        "  tick=time.time()\n",
        "  for f in os.listdir(imgdir_path):\n",
        "    out_path=imgdir_path+str(f)\n",
        "    img = np.asarray(Image.open(out_path))/255.0\n",
        "    print('writing img#{} to csv'.format(img_no))\n",
        "    for index in np.ndindex(img.shape[:]):    \n",
        "      with open(csv_name, 'a') as csvfile:\n",
        "          writer = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "          writer.writerow( [ str(f.split('.')[0])+'_'+str(index[0]+1)+'_'+str(index[1]+1) ]+[ str(img[index[0],index[1]]) ] )\n",
        "    img_no+=1\n",
        "    tock1=time.time()\n",
        "    print('time to copy {}: {}'.format(f,str(tock1-tick)))\n",
        "  tock=time.time()\n",
        "  return 'time taken: '+str(tock-tick)\n",
        "\n",
        "img2csv('datalab/train_cleaned/','train_cleaned.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "writing img#1 to csv\n",
            "time to copy 183.png: 15.499060869216919\n",
            "writing img#2 to csv\n",
            "time to copy 56.png: 25.07726764678955\n",
            "writing img#3 to csv\n",
            "time to copy 92.png: 40.592365741729736\n",
            "writing img#4 to csv\n",
            "time to copy 32.png: 50.14067459106445\n",
            "writing img#5 to csv\n",
            "time to copy 50.png: 59.66117262840271\n",
            "writing img#6 to csv\n",
            "time to copy 182.png: 75.17591857910156\n",
            "writing img#7 to csv\n",
            "time to copy 110.png: 90.73227524757385\n",
            "writing img#8 to csv\n",
            "time to copy 105.png: 106.2534568309784\n",
            "writing img#9 to csv\n",
            "time to copy 138.png: 121.93554043769836\n",
            "writing img#10 to csv\n",
            "time to copy 99.png: 137.37348461151123\n",
            "writing img#11 to csv\n",
            "time to copy 62.png: 146.93444657325745\n",
            "writing img#12 to csv\n",
            "time to copy 59.png: 156.50678420066833\n",
            "writing img#13 to csv\n",
            "time to copy 108.png: 172.0984537601471\n",
            "writing img#14 to csv\n",
            "time to copy 12.png: 181.69309449195862\n",
            "writing img#15 to csv\n",
            "time to copy 119.png: 197.18895030021667\n",
            "writing img#16 to csv\n",
            "time to copy 155.png: 212.7899832725525\n",
            "writing img#17 to csv\n",
            "time to copy 120.png: 228.32787370681763\n",
            "writing img#18 to csv\n",
            "time to copy 140.png: 243.89713287353516\n",
            "writing img#19 to csv\n",
            "time to copy 113.png: 259.40053606033325\n",
            "writing img#20 to csv\n",
            "time to copy 159.png: 275.0515112876892\n",
            "writing img#21 to csv\n",
            "time to copy 114.png: 290.6036567687988\n",
            "writing img#22 to csv\n",
            "time to copy 57.png: 300.1441946029663\n",
            "writing img#23 to csv\n",
            "time to copy 80.png: 315.59467220306396\n",
            "writing img#24 to csv\n",
            "time to copy 147.png: 331.1482448577881\n",
            "writing img#25 to csv\n",
            "time to copy 27.png: 340.6357343196869\n",
            "writing img#26 to csv\n",
            "time to copy 51.png: 350.2235572338104\n",
            "writing img#27 to csv\n",
            "time to copy 179.png: 365.9887354373932\n",
            "writing img#28 to csv\n",
            "time to copy 11.png: 375.5044379234314\n",
            "writing img#29 to csv\n",
            "time to copy 77.png: 390.99943447113037\n",
            "writing img#30 to csv\n",
            "time to copy 47.png: 400.57519459724426\n",
            "writing img#31 to csv\n",
            "time to copy 149.png: 416.0935113430023\n",
            "writing img#32 to csv\n",
            "time to copy 2.png: 425.57581329345703\n",
            "writing img#33 to csv\n",
            "time to copy 146.png: 441.04183983802795\n",
            "writing img#34 to csv\n",
            "time to copy 191.png: 456.4992287158966\n",
            "writing img#35 to csv\n",
            "time to copy 68.png: 465.9638910293579\n",
            "writing img#36 to csv\n",
            "time to copy 45.png: 475.46191596984863\n",
            "writing img#37 to csv\n",
            "time to copy 177.png: 490.93693375587463\n",
            "writing img#38 to csv\n",
            "time to copy 197.png: 506.46287727355957\n",
            "writing img#39 to csv\n",
            "time to copy 167.png: 521.9797468185425\n",
            "writing img#40 to csv\n",
            "time to copy 156.png: 537.5520124435425\n",
            "writing img#41 to csv\n",
            "time to copy 26.png: 547.1165428161621\n",
            "writing img#42 to csv\n",
            "time to copy 185.png: 562.6479594707489\n",
            "writing img#43 to csv\n",
            "time to copy 173.png: 578.2094385623932\n",
            "writing img#44 to csv\n",
            "time to copy 209.png: 593.7667875289917\n",
            "writing img#45 to csv\n",
            "time to copy 165.png: 609.3947906494141\n",
            "writing img#46 to csv\n",
            "time to copy 102.png: 625.0519027709961\n",
            "writing img#47 to csv\n",
            "time to copy 137.png: 640.6853065490723\n",
            "writing img#48 to csv\n",
            "time to copy 158.png: 656.2666103839874\n",
            "writing img#49 to csv\n",
            "time to copy 71.png: 665.8544254302979\n",
            "writing img#50 to csv\n",
            "time to copy 171.png: 681.3121998310089\n",
            "writing img#51 to csv\n",
            "time to copy 201.png: 696.8361113071442\n",
            "writing img#52 to csv\n",
            "time to copy 152.png: 712.3776586055756\n",
            "writing img#53 to csv\n",
            "time to copy 87.png: 727.8892183303833\n",
            "writing img#54 to csv\n",
            "time to copy 9.png: 737.4046597480774\n",
            "writing img#55 to csv\n",
            "time to copy 15.png: 746.927330493927\n",
            "writing img#56 to csv\n",
            "time to copy 198.png: 762.4873440265656\n",
            "writing img#57 to csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "time to copy 65.png: 771.9516253471375\n",
            "writing img#58 to csv\n",
            "time to copy 213.png: 787.4093194007874\n",
            "writing img#59 to csv\n",
            "time to copy 83.png: 802.792445898056\n",
            "writing img#60 to csv\n",
            "time to copy 98.png: 818.5159742832184\n",
            "writing img#61 to csv\n",
            "time to copy 126.png: 833.9696080684662\n",
            "writing img#62 to csv\n",
            "time to copy 24.png: 843.4770398139954\n",
            "writing img#63 to csv\n",
            "time to copy 72.png: 852.9030067920685\n",
            "writing img#64 to csv\n",
            "time to copy 180.png: 868.3621077537537\n",
            "writing img#65 to csv\n",
            "time to copy 174.png: 883.8732032775879\n",
            "writing img#66 to csv\n",
            "time to copy 141.png: 899.2639937400818\n",
            "writing img#67 to csv\n",
            "time to copy 189.png: 914.6497993469238\n",
            "writing img#68 to csv\n",
            "time to copy 30.png: 924.1340477466583\n",
            "writing img#69 to csv\n",
            "time to copy 122.png: 939.6108891963959\n",
            "writing img#70 to csv\n",
            "time to copy 135.png: 954.9622447490692\n",
            "writing img#71 to csv\n",
            "time to copy 194.png: 970.2685871124268\n",
            "writing img#72 to csv\n",
            "time to copy 125.png: 985.6736679077148\n",
            "writing img#73 to csv\n",
            "time to copy 86.png: 1001.0505123138428\n",
            "writing img#74 to csv\n",
            "time to copy 3.png: 1010.5446166992188\n",
            "writing img#75 to csv\n",
            "time to copy 153.png: 1026.033162355423\n",
            "writing img#76 to csv\n",
            "time to copy 8.png: 1035.4939670562744\n",
            "writing img#77 to csv\n",
            "time to copy 63.png: 1045.0124897956848\n",
            "writing img#78 to csv\n",
            "time to copy 162.png: 1060.5674686431885\n",
            "writing img#79 to csv\n",
            "time to copy 84.png: 1076.0173799991608\n",
            "writing img#80 to csv\n",
            "time to copy 212.png: 1091.4473550319672\n",
            "writing img#81 to csv\n",
            "time to copy 66.png: 1100.8979322910309\n",
            "writing img#82 to csv\n",
            "time to copy 53.png: 1110.3798792362213\n",
            "writing img#83 to csv\n",
            "time to copy 44.png: 1119.921618938446\n",
            "writing img#84 to csv\n",
            "time to copy 89.png: 1135.3115391731262\n",
            "writing img#85 to csv\n",
            "time to copy 48.png: 1144.8531520366669\n",
            "writing img#86 to csv\n",
            "time to copy 29.png: 1154.29576253891\n",
            "writing img#87 to csv\n",
            "time to copy 210.png: 1169.7334027290344\n",
            "writing img#88 to csv\n",
            "time to copy 170.png: 1185.1226015090942\n",
            "writing img#89 to csv\n",
            "time to copy 168.png: 1200.5564143657684\n",
            "writing img#90 to csv\n",
            "time to copy 20.png: 1209.999980211258\n",
            "writing img#91 to csv\n",
            "time to copy 60.png: 1219.4319972991943\n",
            "writing img#92 to csv\n",
            "time to copy 107.png: 1234.811671257019\n",
            "writing img#93 to csv\n",
            "time to copy 36.png: 1244.3004467487335\n",
            "writing img#94 to csv\n",
            "time to copy 33.png: 1253.6854665279388\n",
            "writing img#95 to csv\n",
            "time to copy 188.png: 1269.1216197013855\n",
            "writing img#96 to csv\n",
            "time to copy 129.png: 1284.4733560085297\n",
            "writing img#97 to csv\n",
            "time to copy 164.png: 1299.8987152576447\n",
            "writing img#98 to csv\n",
            "time to copy 35.png: 1309.3485934734344\n",
            "writing img#99 to csv\n",
            "time to copy 161.png: 1324.7924427986145\n",
            "writing img#100 to csv\n",
            "time to copy 186.png: 1340.188148021698\n",
            "writing img#101 to csv\n",
            "time to copy 78.png: 1355.6890759468079\n",
            "writing img#102 to csv\n",
            "time to copy 207.png: 1371.0714197158813\n",
            "writing img#103 to csv\n",
            "time to copy 143.png: 1386.4409878253937\n",
            "writing img#104 to csv\n",
            "time to copy 215.png: 1401.7778339385986\n",
            "writing img#105 to csv\n",
            "time to copy 23.png: 1411.21937417984\n",
            "writing img#106 to csv\n",
            "time to copy 144.png: 1426.53302526474\n",
            "writing img#107 to csv\n",
            "time to copy 5.png: 1436.0113492012024\n",
            "writing img#108 to csv\n",
            "time to copy 128.png: 1451.277455329895\n",
            "writing img#109 to csv\n",
            "time to copy 204.png: 1466.5416495800018\n",
            "writing img#110 to csv\n",
            "time to copy 117.png: 1481.9759891033173\n",
            "writing img#111 to csv\n",
            "time to copy 93.png: 1497.332311630249\n",
            "writing img#112 to csv\n",
            "time to copy 17.png: 1506.7450652122498\n",
            "writing img#113 to csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "time to copy 216.png: 1522.0567195415497\n",
            "writing img#114 to csv\n",
            "time to copy 131.png: 1537.373825788498\n",
            "writing img#115 to csv\n",
            "time to copy 111.png: 1552.70428109169\n",
            "writing img#116 to csv\n",
            "time to copy 101.png: 1567.9181008338928\n",
            "writing img#117 to csv\n",
            "time to copy 74.png: 1583.119149684906\n",
            "writing img#118 to csv\n",
            "time to copy 96.png: 1598.2864394187927\n",
            "writing img#119 to csv\n",
            "time to copy 18.png: 1607.6615068912506\n",
            "writing img#120 to csv\n",
            "time to copy 75.png: 1622.9005699157715\n",
            "writing img#121 to csv\n",
            "time to copy 21.png: 1632.2765843868256\n",
            "writing img#122 to csv\n",
            "time to copy 200.png: 1647.5256667137146\n",
            "writing img#123 to csv\n",
            "time to copy 104.png: 1662.8447947502136\n",
            "writing img#124 to csv\n",
            "time to copy 150.png: 1678.1939792633057\n",
            "writing img#125 to csv\n",
            "time to copy 192.png: 1693.5271770954132\n",
            "writing img#126 to csv\n",
            "time to copy 132.png: 1708.8015356063843\n",
            "writing img#127 to csv\n",
            "time to copy 195.png: 1724.1345500946045\n",
            "writing img#128 to csv\n",
            "time to copy 38.png: 1733.5716261863708\n",
            "writing img#129 to csv\n",
            "time to copy 203.png: 1748.8913905620575\n",
            "writing img#130 to csv\n",
            "time to copy 39.png: 1758.3049101829529\n",
            "writing img#131 to csv\n",
            "time to copy 95.png: 1773.6466069221497\n",
            "writing img#132 to csv\n",
            "time to copy 14.png: 1783.0838940143585\n",
            "writing img#133 to csv\n",
            "time to copy 81.png: 1798.3390893936157\n",
            "writing img#134 to csv\n",
            "time to copy 123.png: 1813.6390528678894\n",
            "writing img#135 to csv\n",
            "time to copy 90.png: 1828.923998117447\n",
            "writing img#136 to csv\n",
            "time to copy 116.png: 1844.288366317749\n",
            "writing img#137 to csv\n",
            "time to copy 42.png: 1853.7293524742126\n",
            "writing img#138 to csv\n",
            "time to copy 176.png: 1869.077248096466\n",
            "writing img#139 to csv\n",
            "time to copy 41.png: 1878.5392496585846\n",
            "writing img#140 to csv\n",
            "time to copy 54.png: 1888.0273282527924\n",
            "writing img#141 to csv\n",
            "time to copy 206.png: 1903.5310254096985\n",
            "writing img#142 to csv\n",
            "time to copy 134.png: 1918.9538028240204\n",
            "writing img#143 to csv\n",
            "time to copy 6.png: 1928.4048156738281\n",
            "writing img#144 to csv\n",
            "time to copy 69.png: 1937.850811958313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'time taken: 1937.8511793613434'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "qRgjOvdhr8u6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "cellView": "code",
        "outputId": "f1a48d57-1cf5-4518-82f5-99dce6a2a043",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529241124181,
          "user_tz": -330,
          "elapsed": 5444,
          "user": {
            "displayName": "Tester",
            "photoUrl": "//lh5.googleusercontent.com/-qA8vaqLPJz4/AAAAAAAAAAI/AAAAAAAAABM/Dw8MfZNwdeI/s50-c-k-no/photo.jpg",
            "userId": "111793042070986861735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Functions to download files from collab to local system/gdrive\n",
        "\n",
        "def save_file_to_local(filename):\n",
        "  '''\n",
        "  files.download is useful for downloading small files from collab book to local drive. \n",
        "  Note: for bigger file size > 100MB, try storing file to google drive & download thereafter.\n",
        "  '''\n",
        "  \n",
        "  from google.colab import files\n",
        "\n",
        "  files.download(filename)\n",
        "  \n",
        "def save_file_to_gdrive(name, path):\n",
        "  '''\n",
        "  Upload the file to Drive. See:\n",
        "  https://developers.google.com/drive/v3/reference/files/create\n",
        "  https://developers.google.com/drive/v3/web/manage-uploads\n",
        "  '''\n",
        "  \n",
        "  from googleapiclient.http import MediaFileUpload\n",
        "  from googleapiclient.discovery import build\n",
        "  \n",
        "  drive_service = build('drive', 'v3')\n",
        "  file_metadata = {\n",
        "  'name': name,\n",
        "  'mimeType': 'application/octet-stream'\n",
        "  }\n",
        "  media = MediaFileUpload(path, mimetype='application/octet-stream',resumable=True)\n",
        "  created = drive_service.files().create(body=file_metadata, media_body=media,fields='id').execute()\n",
        "  print('File ID: {}'.format(created.get('id')))\n",
        "  return created\n",
        "\n",
        "save_file_to_gdrive('train_cleaned.csv','/content/train_cleaned.csv')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json\n",
            "183_1_1,1.0\n",
            "183_1_2,1.0\n",
            "183_1_3,1.0\n",
            "183_1_4,1.0\n",
            "183_1_5,1.0\n",
            "****\n",
            "183_1_1,0.8901960784313725\n",
            "183_1_2,0.8823529411764706\n",
            "183_1_3,0.8980392156862745\n",
            "183_1_4,0.8823529411764706\n",
            "183_1_5,0.8705882352941177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Dd5SNpM4vy9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a579a526-ddb0-419d-8c19-20f55d0c9df4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529255339963,
          "user_tz": -330,
          "elapsed": 260268,
          "user": {
            "displayName": "Tester",
            "photoUrl": "//lh5.googleusercontent.com/-qA8vaqLPJz4/AAAAAAAAAAI/AAAAAAAAABM/Dw8MfZNwdeI/s50-c-k-no/photo.jpg",
            "userId": "111793042070986861735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "\n",
        "def csv2np1(input_csv):\n",
        "  import numpy as np\n",
        "  return np.genfromtxt(input_csv,delimiter=',')\n",
        "\n",
        "import time\n",
        "def csv2np(input_csv):\n",
        "  '''\n",
        "  using csv module to read data & np.asarray method to covert to numpy array is 10X faster than using np.genfromtxt()\n",
        "  '''\n",
        "  import csv\n",
        "  import numpy as np\n",
        "  with open(input_csv,'r') as dest_f:\n",
        "      data_iter = csv.reader(dest_f, delimiter = ',', quotechar = '\"')\n",
        "      data = [data for data in data_iter]\n",
        "  np_array = np.asarray(data, dtype = float)    \n",
        "  return np_array\n",
        "\n",
        "tick=time.time()\n",
        "#y_train = csv2np('/content/train_cleaned.csv')\n",
        "y_train1 = csv2np1('/content/train_cleaned.csv')\n",
        "tock=time.time()\n",
        "print(tock-tick)\n",
        "#X_train = csv2np('/content/train.csv')\n",
        "X_train1 = csv2np1('/content/train.csv')\n",
        "tock=time.time()\n",
        "print(tock-tick)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  train_cleaned.csv  train.csv\r\n",
            "125.94951009750366\n",
            "258.1544303894043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ws1wr_C40qXl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1935
        },
        "outputId": "822ccef9-7ac7-49d5-ace3-ce2e3790c3f6",
        "executionInfo": {
          "status": "error",
          "timestamp": 1529255363523,
          "user_tz": -330,
          "elapsed": 3901,
          "user": {
            "displayName": "Tester",
            "photoUrl": "//lh5.googleusercontent.com/-qA8vaqLPJz4/AAAAAAAAAAI/AAAAAAAAABM/Dw8MfZNwdeI/s50-c-k-no/photo.jpg",
            "userId": "111793042070986861735"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def linear_reg_keras(X_train, y_train, y_test, epoch=10, bsize=16):\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers.core import Dense, Activation\n",
        "  model = Sequential()\n",
        "#   model.add(Dense(2,1,init='uniform', activation='linear'))\n",
        "  model.add(Dense(32, input_dim=(28460160,)))\n",
        "  model.add(Activation('linear'))\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(loss='mse', optimizer='rmsprop')\n",
        "\n",
        "  model.fit(X_train, y_train, nb_epoch=epoch, batch_size=bsize,verbose=1)\n",
        "  score = model.evaluate(X_test, y_test, bsize=16)\n",
        "\n",
        "  \n",
        "x=np.transpose(X_train1[:,1])\n",
        "y=np.transpose(y_train1[:,1])\n",
        "print(y.shape)\n",
        "print(x.shape)\n",
        "\n",
        "linear_reg_keras(x, y, x, epoch=1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28460160,)\n",
            "(28460160,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    478\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       if (not isinstance(value, compat.bytes_or_text_types) and\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'tuple'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4b4a37cf95a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mlinear_reg_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-4b4a37cf95a8>\u001b[0m in \u001b[0;36mlinear_reg_keras\u001b[0;34m(X_train, y_train, y_test, epoch, bsize)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#   model.add(Dense(2,1,init='uniform', activation='linear'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28460160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 x = Input(batch_shape=batch_shape,\n\u001b[1;32m    492\u001b[0m                           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                           name=layer.name + '_input')\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0;31m# This will build the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m   1455\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m   1458\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m   1364\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m                                          name=self.name)\n\u001b[0m\u001b[1;32m   1367\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1806\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1808\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   4844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4845\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4846\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4847\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4848\u001b[0m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error converting %s to a TensorShape: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     raise ValueError(\"Error converting %s to a TensorShape: %s.\" % (arg_name,\n",
            "\u001b[0;31mTypeError\u001b[0m: Error converting shape to a TensorShape: int() argument must be a string, a bytes-like object or a number, not 'tuple'."
          ]
        }
      ]
    }
  ]
}